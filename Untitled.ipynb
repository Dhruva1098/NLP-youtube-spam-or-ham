{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/dhruv/Documents/DS-class/classification/soh/Youtube05-Shakira.csv\", encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(labels=['COMMENT_ID','AUTHOR','DATE',],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import string\n",
    "import pandas as pd\n",
    "def clean_text_round1(text):\n",
    "    #makes lowercase, removes brackets, removes punct\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub( u\"(\\ud83d[\\ude00-\\ude4f])|\", '', text)\n",
    "    text = re.sub('\"\\ufeff\"', '', text)\n",
    "    \n",
    "    return text\n",
    "r1 = lambda x: clean_text_round1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice song﻿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i love song ﻿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i love song ﻿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lets make it first female to reach one billio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shakira is best for worldcup﻿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>i love this song because we sing it at camp al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>i love this song for two reasons  is about afr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>shakira u are so wiredo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>shakira is the best dancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               CONTENT\n",
       "0                                           nice song﻿\n",
       "1                                        i love song ﻿\n",
       "2                                        i love song ﻿\n",
       "3     lets make it first female to reach one billio...\n",
       "4                        shakira is best for worldcup﻿\n",
       "..                                                 ...\n",
       "365  i love this song because we sing it at camp al...\n",
       "366  i love this song for two reasons  is about afr...\n",
       "367                                                wow\n",
       "368                            shakira u are so wiredo\n",
       "369                         shakira is the best dancer\n",
       "\n",
       "[370 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = pd.DataFrame(data.CONTENT.apply(r1))\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_round2(text):\n",
    "    #other punctuation, and non-sensical text missed\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    return text\n",
    "r2 = lambda x: clean_text_round2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = pd.DataFrame(data_clean.CONTENT.apply(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(text): # removes all non-ascii characters\n",
    "    return ''.join(i for i in text if ord(i)<128)\n",
    "data_clean.CONTENT = data_clean.CONTENT.apply(remove_non_ascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[nice, song]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[i, love, song, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[i, love, song, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[, lets, make, it, first, female, to, reach, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[shakira, is, best, for, worldcup]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>[i, love, this, song, because, we, sing, it, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>[i, love, this, song, for, two, reasons, , is,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>[wow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>[shakira, u, are, so, wiredo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>[shakira, is, the, best, dancer]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               CONTENT\n",
       "0                                         [nice, song]\n",
       "1                                    [i, love, song, ]\n",
       "2                                    [i, love, song, ]\n",
       "3    [, lets, make, it, first, female, to, reach, o...\n",
       "4                   [shakira, is, best, for, worldcup]\n",
       "..                                                 ...\n",
       "365  [i, love, this, song, because, we, sing, it, a...\n",
       "366  [i, love, this, song, for, two, reasons, , is,...\n",
       "367                                              [wow]\n",
       "368                      [shakira, u, are, so, wiredo]\n",
       "369                   [shakira, is, the, best, dancer]\n",
       "\n",
       "[370 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = pd.DataFrame(data_clean.CONTENT.str.split(' '))\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(CONTENT=split['CONTENT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "#i am specifying english for optimisation (?) \n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "data['S_CONTENT'] = data['CONTENT'].apply(lambda x: [stemmer.stem(y) for y in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stopwords(n):\n",
    "    list = n['S_CONTENT']\n",
    "    useful = [w for w in list if not w in stops]\n",
    "    return(useful)\n",
    "\n",
    "data['STEMMED'] = data.apply(remove_stopwords, axis =1)\n",
    "data['STR'] = data.STEMMED.apply(lambda x: ', '.join([str(i) for i in x]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting\n",
    "shuffle_data = data.sample(frac=1)\n",
    "test_set = data.sample(111)\n",
    "train_set = data[~data.isin(test_set)]\n",
    "train_set.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data[\"CONTENT\"] \n",
    "del data[\"S_CONTENT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = []\n",
    "for words in data.STEMMED:\n",
    "    for val in words:\n",
    "        temp1.append(val)\n",
    "vocab = []\n",
    "for val in temp1:\n",
    "    if val not in vocab:\n",
    "        vocab.append(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = train_set[train_set['CLASS']==1]\n",
    "ham = train_set[train_set['CLASS']==0]\n",
    "Z = []\n",
    "for words in spam.STEMMED:\n",
    "    for val in words:\n",
    "        Z.append(val)\n",
    "BOW_S = []\n",
    "for val in Z:\n",
    "    if val not in BOW_S:\n",
    "        BOW_S.append(val)\n",
    "L = []\n",
    "for words in ham.STEMMED:\n",
    "    for val in words:\n",
    "        L.append(val)\n",
    "BOW_H = []\n",
    "for val in L:\n",
    "    if val not in BOW_H:\n",
    "        BOW_H.append(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "negF = Counter(Z)\n",
    "posF = Counter(L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet):\n",
    "    n = 0\n",
    "    p = 0\n",
    "    for word in tweet:\n",
    "        if word in negF.keys():\n",
    "            n += negF[word]\n",
    "        if word in posF.keys():\n",
    "            p +=  posF[word]\n",
    "    X = [1, p, n]\n",
    "    return X\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((259,3))\n",
    "temp = []\n",
    "for row in train_set.itertuples(index = True):\n",
    "    \n",
    "    lst = extract_features(getattr(row, \"STEMMED\"))\n",
    "    temp.append(lst)\n",
    " \n",
    "X = np.array(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for row in train_set.itertuples(index = True):\n",
    "    lst = getattr(row, \"CLASS\")\n",
    "    temp.append(lst)\n",
    "Y = np.array(temp)\n",
    "y = Y.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import numpy as np\n",
    " \n",
    "class LR:\n",
    "     \n",
    "    def sigmoid(self,z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "     \n",
    "    def add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "     \n",
    "    def loss_func(self,X, y, weights):                 \n",
    "        m =len(X)                \n",
    "        yhat = sigmoid(np.dot(X, weights))        \n",
    "        predict_1 = y * np.log(yhat)\n",
    "        predict_0 = (1 - y) * np.log(1 - yhat)        \n",
    "        return -sum(predict_1 + predict_0) / m\n",
    "     \n",
    "    def fit(self,X,y,epochs=25,learning_rate=0.05):\n",
    "        loss = []\n",
    "         \n",
    "        X = self.add_intercept(X)\n",
    "         \n",
    "        weights = np.random.rand(X.shape[1])\n",
    "        N = len(X)\n",
    " \n",
    "        for _ in range(epochs):\n",
    "            z = np.dot(X,weights)\n",
    "            y_hat = sigmoid(z)\n",
    "            weights -= learning_rate * (X.T @ (y_hat-y))/N\n",
    "            loss.append(self.loss_func(X,y,weights))\n",
    "        self.weights = weights\n",
    "        self.loss = loss\n",
    "        print(weights)\n",
    "         \n",
    "    def predict(self, X): \n",
    "        X = self.add_intercept(X)\n",
    "        z = np.dot(X, self.weights)\n",
    "        #Binary result\n",
    "        return [1 if i > 0.5 else 0 for i in self.sigmoid(z)]\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-dc64dee5606b>:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n",
      "<ipython-input-30-446e5199b7bd>:15: RuntimeWarning: divide by zero encountered in log\n",
      "  predict_1 = y * np.log(yhat)\n",
      "<ipython-input-30-446e5199b7bd>:16: RuntimeWarning: divide by zero encountered in log\n",
      "  predict_0 = (1 - y) * np.log(1 - yhat)\n",
      "<ipython-input-30-446e5199b7bd>:16: RuntimeWarning: invalid value encountered in multiply\n",
      "  predict_0 = (1 - y) * np.log(1 - yhat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.49034177 -4.9898005  -2.89116689  0.6057258 ]\n"
     ]
    }
   ],
   "source": [
    "lr = LR()\n",
    "lr.fit(X_train,y_train,epochs=100000,learning_rate=0.005)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predection = lr.predict(X_test)\n",
    "len(predection)\n",
    "pred = np.array(predection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = []\n",
    "for (e1 , e2) in zip(pred, y_test):\n",
    "    if e1 == e2:\n",
    "        validation.append(1)\n",
    "    if e1 != e2:\n",
    "        validation.append(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9102564102564102\n"
     ]
    }
   ],
   "source": [
    "acc = sum(validation)/len(validation)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
